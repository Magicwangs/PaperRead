{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction 因为写博客太麻烦, 所以改用gitbook记录平时看的一些paper或是好的书. No Translation, Only Keypoint. TODO 各个norm方式的整理 各个优化方式的整理 邓丹 MLY-zh-cn.pdf Pixor: Real-time 3d object detection from point clouds. HDNET: Exploiting HD Maps for 3D Object Detection pointnet思路的系列 Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling R-FCN系列， SSD系列， Yolo系列 STDN: Scale-Transferrable Object Detection Check一下之前遗漏的 ECCV2018目标检测（object detection）算法总览 CVPR2018 目标检测算法总览(最新的目标检测论文) 规划一下论文的思路 face++组工作介绍 目标检测还有什么好做的？ By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-10 14:56:25 "},"BASENET/":{"url":"BASENET/","title":"BASENET","keywords":"","body":"BASENET ATTENTION ResNet Residual Attention Network for Image Classification By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2018-12-24 15:08:01 "},"BASENET/Residual_Attention_Network_for_Image_Classification.html":{"url":"BASENET/Residual_Attention_Network_for_Image_Classification.html","title":"Residual Attention Network for Image Classification","keywords":"","body":"Residual Attention Network for Image Classification Authors: Fei Wang, Mengqing Jiang Link: https://arxiv.org/abs/1704.06904 Tags: SenseTime Attention Year: 2017 Official Code: https://github.com/fwang91/residual-attention-network Motivation Attention机制不仅仅可以帮助channel的加强, 还可以增强物体在不同位置的表达 KeyWord The Attention Module is designed to suppress noise while keeping useful information by applying dot product between feature and soft mask.However, repeated dot product will lead to severe degradation of both useful and useless information in this process. The attention residual learning can relieve signal attenuation using identical mapping, which enhances the feature contrast. Bottom-up top-down feedforward attention 使用类似于Stacked Hourglass 沙漏型的结构 在feature map上增加一个soft weight Bottem-up 结构产生了低分辨率但是强语义信息的Feature Map Top-Down 结构则 负责产生 高分辨率的Dense的结果 Skip-Connect 结构来帮助信息的融合 Trunk Branch and Mask Branch Trunk主干分支: PreAct 的残差块(Resnet V2) -- T(x) Mask分支: bottom-up top-down 结构 --和 T(x) 相同Size的 M(x) 最终 H(x)=M(x)∗T(x)H(x) = M(x)*T(x)H(x)=M(x)∗T(x) 直接点乘 WHY 如果只是简单的堆叠Attention模块,会导致性能的下降 因为 mask的值(经过sigmoid)是 0-1, 反复的乘以这个mask 会导致 feature map的值越来越小 soft mask 可能会破坏Trunk分支的特征 所以最终 H(x)=(1+M(x))∗F(x)H(x) = (1+M(x)) * F(x)H(x)=(1+M(x))∗F(x) 其中 0M(x)100M(x)1 希望 mask能够抑制主干分支的噪声, 增强重要的特征 Soft Mask Branch 使用 max-pool来降低增大感受野,双线性插值来增大分辨率 bottom-up和top-down对称 Mask分支的主要目的还是增强 Trunk分支 Spatial Attention and Channel Attention 只需要通过一个 sigmoid 就能实现最佳的效果 不需要 SENet那样的 仅对通道 weight或是仅对空间 weight By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2018-12-24 15:08:01 "},"DETECTION/":{"url":"DETECTION/","title":"DETECTION","keywords":"","body":"DETECTION First Of All mean Average precision(mAP) mAP定义及相关概念mAP: mean Average Precision, 即各类别AP的平均值 AP: PR曲线下面积，后文会详细讲解 PR曲线: Precision-Recall曲线 Precision: TP / (TP + FP) Recall: TP / (TP + FN) TP: IoU>{0,0.1,...,1}的检测框数量（同一Ground Truth只计算一次） FP: IoU FN: 没有检测到的GT的数量 在计算AP的过程中, 首先需要有一个IoU阈值, 来判断这个框是不是可以输出的框 然后 再根据输出的框 和GT的IoU 来计算 AP wrt: with respect to 的缩写, 相对于 R-CNN Object Detection Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks R-CNN Object Detection Cascade R-CNN: Delving into High Quality Object Detection BackBoneDetNet: A Backbone network for Object Detection By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2018-12-24 15:08:01 "},"DETECTION/Faster_R_CNN.html":{"url":"DETECTION/Faster_R_CNN.html","title":"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks","keywords":"","body":"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks Authors: Magic Link: url Tags: Attention Year: 2017 Official Code: url Motivation KeyWord Detail WHY 目前回归就是单纯的 关于 we bbox_transform_inv 中normal的问题is usually normalized by its mean and variance, i.e. δx is replaced by δx ′ = (δx − µx)/σx. This is widely used in the literature [27, 1, 4, 21, 14]. https://github.com/facebookresearch/Detectron/blob/8170b25b425967f8f1c7d715bea3c5b8d9536cd8/detectron/utils/boxes.py https://github.com/facebookresearch/Detectron/blob/ffb87f4cf73276ef53feb65195e6a262d8ee5bae/detectron/core/config.py By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2018-12-24 15:08:01 "},"DETECTION/Cascade_R_CNN.html":{"url":"DETECTION/Cascade_R_CNN.html","title":"Cascade R-CNN: Delving into High Quality Object Detection","keywords":"","body":"Cascade R-CNN: Delving into High Quality Object Detection Authors: Zhaowei Cai, Nuno Vasconcelos Link: https://arxiv.org/abs/1712.00726 Tags: R-CNN Object Detection Year: 2017 Official Code: https://github.com/zhaoweicai/cascade-rcnn Motivation 在目标检测时, 需要分类和回归, 通过IoU来判断样本是否是正样本, IoU的选取对train 和 inference的影响都很大: 图a,b 表示的是如果IoU的阈值选择的过低, 就会出现 过多的 “close” false positives, 这部分样本和 图c中横轴表示proposal和GT的IoU，纵轴的是经过box reg后和GT的IoU, 不同曲线表示不同IoU阈值训练出的detector 在0.55-0.6的范围内阈值为0.5的detector性能最好，在0.6-0.75阈值为0.6的detector性能最佳，而到了0.75之后就是阈值为0.7的detector了 只有proposal自身的阈值和训练器训练用的阈值较为接近的时候，训练器的性能才最好,如果两个阈值相距比较远，就会出现mismatch的问题 图d中横轴表示 是否认为Proposal是真框, 纵轴表示 根据输出的框计算的AP 如果只是 单纯的提高 IoU的阈值, 会改变正负样本的数据分布, 会导致进一步的不平衡, 导致过拟合 可以发现图c中 大部分线条都是在y=x的灰色线条之上的， 这就说明某个proposal在经过detector后的IoU几乎必然是增加的，那么再经过一个更大阈值训练的detector，它的IoU就会更好。 KeyWord a single detector can only be optimal for a single quality level. the output of a detector trained with a certain IoU threshold is a good distribution to train the detector of the next higher IoU threshold. the resampling procedure of the Cascade R-CNN does not aim to mine hard negatives. Instead, by adjusting bounding boxes, each stage aims to find a good set of close false positives for training the next stage. Detail Cascade R-CNN 类似于GBDT的思想, 每一级的detector都是一个弱detector, 但是都是对上一级的分类和回归后的结果进行调整 图b是iterative BBox 交替的训练同一个Detector, 但是iou threshold 始终是0.5, 没有真正改善问题, 而且 bbox 的分布一直在改变, 实际上这个Detector是很难训练的, 下图就是iterative BBox 图c是通过ensemble不同 IoU阈值的detector, 但是inference的时候需要ensemble,没有根本上改变这个问题 每个阶段都需要 对偏移 (x,y,w,h)(x, y, w, h)(x,y,w,h) be normalized by its mean and variance for effective multi-task learning. 每个阶段的损失包括分类和回归损失 Cascade R-CNN实际上有四个阶段, 一个RPN和三个Detection(分别选择阈值为 0.5,0.6,0.7的), 在RPN阶段还是和faster rcnn一样, 2000个框,iou阈值为0.7, 剩下的三个Detector就是直接在 输出的 2000个框中 迭代回归, 分类的阈值就是0.5, 每个阶段都是新的roipooling+2∗fc+(cls/reg)roi pooling+2*fc+(cls/reg)roipooling+2∗fc+(cls/reg) Discussion From Others 本文探讨了目标检测中长期以来无人问津但非常重要的问题——IoU阈值选取问题，是极具启发性的一篇工作，作者结合传统方法中的cascade思想和当前主流的Faster R-CNN检测框架，将two-stage方法在现有数据集上将检测性能又提升到了一个新高度。抛开文中大量的实验分析不谈，当我们重新审视当前目标检测算法两大主流框架（Faster R-CNN和SSD）时，一个值得思考的问题是为什么Faster R-CNN的准确率要比SSD高笔者认为这其中的一个关键是：Faster R-CNN完成了对目标候选框的两次预测，其中RPN一次，后面的检测器一次。而本文作者则更进一步，将后面检测器部分堆叠了几个级联模块，并采用不同的IoU阈值训练，进一步提升了Faster R-CNN的准确率。进而我们思考这种提升的上限什么时候会出现？表4表明cascade R-CNN在stage3时性能就已经达到饱和，这和我们的预期还是有一定差距的，如何进一步提升cascade的上限，是值得进一步探索的问题。 By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2018-12-24 15:08:01 "},"DETECTION/DetNet.html":{"url":"DETECTION/DetNet.html","title":"DetNet: A Backbone network for Object Detection","keywords":"","body":"DetNet: A Backbone network for Object Detection Authors: Zeming Li, Chao Peng, Gang Yu, Xiangyu Zhang, Yangdong Deng, Jian Sun Link: https://arxiv.org/abs/1804.06215 Tags: BackBone 水文 Year: 2018 Official Code: Not Official Released Implementation: https://github.com/tsing-cv/DetNet Motivation BackBone For Object Detection Need: 相对与图片分类, 需要更多的中间层(FPN,RetinaNet) 目标检测 除了 识别目标, 还需要定位目标 下采样使得感受野增大, 同时也使得定位信息丢失 目标: 保持空间分辨率, 同时增大感受野 原来的图片分类网络存在的问题 目标检测 和 分类网络的 stage可能不一样, 比如FPN还需要 上采样的层 层越深, 感受野变大, 但物体的边界也变得模糊, 导致不能回归出好的边界 小物体的丢失 Detail 两个问题 保留较高的分辨率会带来计算量和内存消耗的增加 不下采样, 语义信息不够 前四层和ResnNet一样 使用孔卷积保持分辨率 和FPN, 上采样之后 直接相加 然后过一个卷积层融合 By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2018-12-24 15:08:01 "},"3D/":{"url":"3D/","title":"3D","keywords":"","body":"3D By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2018-12-24 15:08:01 "},"MORE/":{"url":"MORE/","title":"MORE","keywords":"","body":"MORE BatchNorm 我知道的关于BN的一切 GitBook AboutGitBook By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2018-12-24 15:08:06 "},"MORE/More_Batch_Norm.html":{"url":"MORE/More_Batch_Norm.html","title":"Batch Norm","keywords":"","body":"我知道的关于BN的一切 Authors: Magic Tags: BatchNorm Year: Alive Summary WHAT HOW DETAIL need read bn的主要作用是控制数值区间，让比较深的网络训练起来稳定性比较好，更不容易爆炸。但是初始化和调参其实可以部分解决这个问题，能不用bn的时候还是尽量不要用，尤其是做一个新的问题的时候，不要想当然就把bn塞进去。 By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2018-12-27 16:19:43 "},"MORE/AboutGitBook.html":{"url":"MORE/AboutGitBook.html","title":"About GitBook","keywords":"","body":"AboutGitBook 安装 sudo npm install -g gitbook-cli 基本命令 gitbook init 初始化仓库, 可以根据SUMMARY.md的内容自行生成目录 gitbook build 可以不设置输出路径, 默认保存在_book目录下 gitbook install 根据book.json下载配置插件 gitbook配置 我的配置 同步coding和github coding page只支持 master和coding-pages的分支启动 coding page服务 github 默认支持 gh-pages 开启github page 服务 每次新建一个branch, 需要新建 .gitignore, 防止 _book 被更新到 git 中,这样 _book就成为一个与各个分支都不相关的目录, 不会git checkout的过程中丢失 各分支建立后, 同步脚本如下 gitbook build git checkout master git add . git commit -m $1 git push -u both master git checkout gh-pages cp -r _book/* . git add . git commit -m $1 git push -u origin gh-pages git checkout coding-pages cp -r _book/* . git add . git commit -m $1 git push -u coding coding-pages git checkout master 修改主题 可以直接修改 主题的css vim node_modules/gitbook-plugin-theme-comscore/book/test.css Reference Publish GitBook to Your GitHub Pages By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2018-12-24 15:08:06 "}}