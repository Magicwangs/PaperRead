{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction 因为写博客太麻烦, 所以改用gitbook记录平时看的一些paper或是好的书. No Translation, Only Keypoint. TODO 各个norm方式的整理 各个优化方式的整理 邓丹 MLY-zh-cn.pdf Pixor: Real-time 3d object detection from point clouds. HDNET: Exploiting HD Maps for 3D Object Detection pointnet思路的系列 Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling R-FCN系列， SSD系列， Yolo系列 STDN: Scale-Transferrable Object Detection Check一下之前遗漏的 ECCV2018目标检测（object detection）算法总览 CVPR2018 目标检测算法总览(最新的目标检测论文) 规划一下论文的思路 face++组工作介绍 目标检测还有什么好做的？ Scale-Aware Trident Networks for Object Detection 卡尔曼滤波、匈牙利匹配算法多目标追踪 By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-14 21:38:10 "},"BASENET/":{"url":"BASENET/","title":"BASENET","keywords":"","body":"BASENET ATTENTION ResNet Residual Attention Network for Image Classification By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-14 21:38:10 "},"BASENET/Residual_Attention_Network_for_Image_Classification.html":{"url":"BASENET/Residual_Attention_Network_for_Image_Classification.html","title":"Residual Attention Network for Image Classification","keywords":"","body":"Residual Attention Network for Image Classification Authors: Fei Wang, Mengqing Jiang Link: https://arxiv.org/abs/1704.06904 Tags: SenseTime Attention Year: 2017 Official Code: https://github.com/fwang91/residual-attention-network Motivation Attention机制不仅仅可以帮助channel的加强, 还可以增强物体在不同位置的表达 KeyWord The Attention Module is designed to suppress noise while keeping useful information by applying dot product between feature and soft mask.However, repeated dot product will lead to severe degradation of both useful and useless information in this process. The attention residual learning can relieve signal attenuation using identical mapping, which enhances the feature contrast. Bottom-up top-down feedforward attention 使用类似于Stacked Hourglass 沙漏型的结构 在feature map上增加一个soft weight Bottem-up 结构产生了低分辨率但是强语义信息的Feature Map Top-Down 结构则 负责产生 高分辨率的Dense的结果 Skip-Connect 结构来帮助信息的融合 Trunk Branch and Mask Branch Trunk主干分支: PreAct 的残差块(Resnet V2) -- T(x) Mask分支: bottom-up top-down 结构 --和 T(x) 相同Size的 M(x) 最终 H(x)=M(x)∗T(x)H(x) = M(x)*T(x)H(x)=M(x)∗T(x) 直接点乘 WHY 如果只是简单的堆叠Attention模块,会导致性能的下降 因为 mask的值(经过sigmoid)是 0-1, 反复的乘以这个mask 会导致 feature map的值越来越小 soft mask 可能会破坏Trunk分支的特征 所以最终 H(x)=(1+M(x))∗F(x)H(x) = (1+M(x)) * F(x)H(x)=(1+M(x))∗F(x) 其中 0M(x)100M(x)1 希望 mask能够抑制主干分支的噪声, 增强重要的特征 Soft Mask Branch 使用 max-pool来降低增大感受野,双线性插值来增大分辨率 bottom-up和top-down对称 Mask分支的主要目的还是增强 Trunk分支 Spatial Attention and Channel Attention 只需要通过一个 sigmoid 就能实现最佳的效果 不需要 SENet那样的 仅对通道 weight或是仅对空间 weight By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-14 21:38:10 "},"DETECTION/":{"url":"DETECTION/","title":"DETECTION","keywords":"","body":"DETECTION First Of All mean Average precision(mAP) mAP定义及相关概念mAP: mean Average Precision, 即各类别AP的平均值 AP: PR曲线下面积，后文会详细讲解 PR曲线: Precision-Recall曲线 Precision: TP / (TP + FP) Recall: TP / (TP + FN) TP: IoU>{0,0.1,...,1}的检测框数量（同一Ground Truth只计算一次） FP: IoU FN: 没有检测到的GT的数量 在计算AP的过程中, 首先需要有一个IoU阈值, 来判断这个框是不是可以输出的框 然后 再根据输出的框 和GT的IoU 来计算 AP wrt: with respect to 的缩写, 相对于 R-CNN Object Detection Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks R-CNN Object Detection Cascade R-CNN: Delving into High Quality Object Detection BackBoneDetNet: A Backbone network for Object Detection By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-14 21:38:10 "},"DETECTION/Faster_R_CNN.html":{"url":"DETECTION/Faster_R_CNN.html","title":"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks","keywords":"","body":"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks Authors: Magic Link: url Tags: Attention Year: 2017 Official Code: url Motivation KeyWord Detail WHY 目前回归就是单纯的 关于 we bbox_transform_inv 中normal的问题is usually normalized by its mean and variance, i.e. δx is replaced by δx ′ = (δx − µx)/σx. This is widely used in the literature [27, 1, 4, 21, 14]. https://github.com/facebookresearch/Detectron/blob/8170b25b425967f8f1c7d715bea3c5b8d9536cd8/detectron/utils/boxes.py https://github.com/facebookresearch/Detectron/blob/ffb87f4cf73276ef53feb65195e6a262d8ee5bae/detectron/core/config.py By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-14 21:38:10 "},"DETECTION/Cascade_R_CNN.html":{"url":"DETECTION/Cascade_R_CNN.html","title":"Cascade R-CNN: Delving into High Quality Object Detection","keywords":"","body":"Cascade R-CNN: Delving into High Quality Object Detection Authors: Zhaowei Cai, Nuno Vasconcelos Link: https://arxiv.org/abs/1712.00726 Tags: R-CNN Object Detection Year: 2017 Official Code: https://github.com/zhaoweicai/cascade-rcnn Motivation 在目标检测时, 需要分类和回归, 通过IoU来判断样本是否是正样本, IoU的选取对train 和 inference的影响都很大: 图a,b 表示的是如果IoU的阈值选择的过低, 就会出现 过多的 “close” false positives, 这部分样本和 图c中横轴表示proposal和GT的IoU，纵轴的是经过box reg后和GT的IoU, 不同曲线表示不同IoU阈值训练出的detector 在0.55-0.6的范围内阈值为0.5的detector性能最好，在0.6-0.75阈值为0.6的detector性能最佳，而到了0.75之后就是阈值为0.7的detector了 只有proposal自身的阈值和训练器训练用的阈值较为接近的时候，训练器的性能才最好,如果两个阈值相距比较远，就会出现mismatch的问题 图d中横轴表示 是否认为Proposal是真框, 纵轴表示 根据输出的框计算的AP 如果只是 单纯的提高 IoU的阈值, 会改变正负样本的数据分布, 会导致进一步的不平衡, 导致过拟合 可以发现图c中 大部分线条都是在y=x的灰色线条之上的， 这就说明某个proposal在经过detector后的IoU几乎必然是增加的，那么再经过一个更大阈值训练的detector，它的IoU就会更好。 KeyWord a single detector can only be optimal for a single quality level. the output of a detector trained with a certain IoU threshold is a good distribution to train the detector of the next higher IoU threshold. the resampling procedure of the Cascade R-CNN does not aim to mine hard negatives. Instead, by adjusting bounding boxes, each stage aims to find a good set of close false positives for training the next stage. Detail Cascade R-CNN 类似于GBDT的思想, 每一级的detector都是一个弱detector, 但是都是对上一级的分类和回归后的结果进行调整 图b是iterative BBox 交替的训练同一个Detector, 但是iou threshold 始终是0.5, 没有真正改善问题, 而且 bbox 的分布一直在改变, 实际上这个Detector是很难训练的, 下图就是iterative BBox 图c是通过ensemble不同 IoU阈值的detector, 但是inference的时候需要ensemble,没有根本上改变这个问题 每个阶段都需要 对偏移 (x,y,w,h)(x, y, w, h)(x,y,w,h) be normalized by its mean and variance for effective multi-task learning. 每个阶段的损失包括分类和回归损失 Cascade R-CNN实际上有四个阶段, 一个RPN和三个Detection(分别选择阈值为 0.5,0.6,0.7的), 在RPN阶段还是和faster rcnn一样, 2000个框,iou阈值为0.7, 剩下的三个Detector就是直接在 输出的 2000个框中 迭代回归, 分类的阈值就是0.5, 每个阶段都是新的roipooling+2∗fc+(cls/reg)roi pooling+2*fc+(cls/reg)roipooling+2∗fc+(cls/reg) Discussion From Others 本文探讨了目标检测中长期以来无人问津但非常重要的问题——IoU阈值选取问题，是极具启发性的一篇工作，作者结合传统方法中的cascade思想和当前主流的Faster R-CNN检测框架，将two-stage方法在现有数据集上将检测性能又提升到了一个新高度。抛开文中大量的实验分析不谈，当我们重新审视当前目标检测算法两大主流框架（Faster R-CNN和SSD）时，一个值得思考的问题是为什么Faster R-CNN的准确率要比SSD高笔者认为这其中的一个关键是：Faster R-CNN完成了对目标候选框的两次预测，其中RPN一次，后面的检测器一次。而本文作者则更进一步，将后面检测器部分堆叠了几个级联模块，并采用不同的IoU阈值训练，进一步提升了Faster R-CNN的准确率。进而我们思考这种提升的上限什么时候会出现？表4表明cascade R-CNN在stage3时性能就已经达到饱和，这和我们的预期还是有一定差距的，如何进一步提升cascade的上限，是值得进一步探索的问题。 By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-14 21:38:10 "},"DETECTION/DetNet.html":{"url":"DETECTION/DetNet.html","title":"DetNet: A Backbone network for Object Detection","keywords":"","body":"DetNet: A Backbone network for Object Detection Authors: Zeming Li, Chao Peng, Gang Yu, Xiangyu Zhang, Yangdong Deng, Jian Sun Link: https://arxiv.org/abs/1804.06215 Tags: BackBone 水文 Year: 2018 Official Code: Not Official Released Implementation: https://github.com/tsing-cv/DetNet Motivation BackBone For Object Detection Need: 相对与图片分类, 需要更多的中间层(FPN,RetinaNet) 目标检测 除了 识别目标, 还需要定位目标 下采样使得感受野增大, 同时也使得定位信息丢失 目标: 保持空间分辨率, 同时增大感受野 原来的图片分类网络存在的问题 目标检测 和 分类网络的 stage可能不一样, 比如FPN还需要 上采样的层 层越深, 感受野变大, 但物体的边界也变得模糊, 导致不能回归出好的边界 小物体的丢失 Detail 两个问题 保留较高的分辨率会带来计算量和内存消耗的增加 不下采样, 语义信息不够 前四层和ResnNet一样 使用孔卷积保持分辨率 和FPN, 上采样之后 直接相加 然后过一个卷积层融合 By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-14 21:38:10 "},"3D/":{"url":"3D/","title":"3D","keywords":"","body":"3D By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-14 21:38:10 "},"MORE/":{"url":"MORE/","title":"MORE","keywords":"","body":"MORE GitBook AboutGitBook BatchNorm 我知道的关于BN的一切 WeChat 张小龙微信公开课2019 Optimization以静制动 Dynamic Batching MXNet MXNet Design Concepts By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-15 10:12:08 "},"MORE/AboutGitBook.html":{"url":"MORE/AboutGitBook.html","title":"About GitBook","keywords":"","body":"AboutGitBook 安装 sudo npm install -g gitbook-cli 基本命令 gitbook init 初始化仓库, 可以根据SUMMARY.md的内容自行生成目录 gitbook build 可以不设置输出路径, 默认保存在_book目录下 gitbook install 根据book.json下载配置插件 gitbook配置 我的配置 同步coding和github coding page只支持 master和coding-pages的分支启动 coding page服务 github 默认支持 gh-pages 开启github page 服务 每次新建一个branch, 需要新建 .gitignore, 防止 _book 被更新到 git 中,这样 _book就成为一个与各个分支都不相关的目录, 不会git checkout的过程中丢失 各分支建立后, 同步脚本如下 gitbook build git checkout master git add . git commit -m $1 git push -u both master git checkout gh-pages cp -r _book/* . git add . git commit -m $1 git push -u origin gh-pages git checkout coding-pages cp -r _book/* . git add . git commit -m $1 git push -u coding coding-pages git checkout master 修改主题 可以直接修改 主题的css vim node_modules/gitbook-plugin-theme-comscore/book/test.css Reference Publish GitBook to Your GitHub Pages By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-14 21:38:10 "},"MORE/More_Batch_Norm.html":{"url":"MORE/More_Batch_Norm.html","title":"Batch Norm","keywords":"","body":"我知道的关于BN的一切 Authors: Magic Tags: BatchNorm Year: Alive Summary WHAT HOW DETAIL need read bn的主要作用是控制数值区间，让比较深的网络训练起来稳定性比较好，更不容易爆炸。但是初始化和调参其实可以部分解决这个问题，能不用bn的时候还是尽量不要用，尤其是做一个新的问题的时候，不要想当然就把bn塞进去。 By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-14 21:38:10 "},"MORE/WeChat.html":{"url":"MORE/WeChat.html","title":"张小龙微信公开课2019","keywords":"","body":"张小龙微信公开课2019 Authors: 张小龙 Link: https://v.qq.com/x/cover/u8pu8q0wmq0fv8a.html Tags: WeChat Year: 2019 KeyWord 把想象的空间留给每个用户自己，十亿用户会有十亿不同的理解，他自己能找到打动他的那一个点。 在我看过来与众不同就是优秀的代名词。我比较惊讶的是，微信的与众不同并不是他想特别的办法与众不同，而是他守住一些做产品的底线就与众不同了。 如果一个新的产品没有获得自然的增长的曲线，我们就不应该推广它, 微信这样一个产品对用户有没有构成一个吸引力，用户愿意不愿意自发传播它，如果用户不愿意，我们怎么样推广它，也是没有意义的。 原动力是你内心深处很深的认知和期望，它很强大，以至于说它可以坚持很久，并且克服很多困难都要去做到它。这样讲是跟初心是有一点区别的，就是更深层次的期望达到的理想或者目标。 让创造价值的人体现价值 朋友圈本意是朋友互相展现互相生活或者推广自己人设的地方，而不是推广阅读的地方，阅读只是它辅助的一个部分 我透过它的眼睛看到他的世界 对用户的态度必须是善良的态度，而不是一种套路的态度 这种善良是基于理性之上的善良，如果是非理性的善良是愚昧的善良，善良本质是一种能力。 对于团队来讲养成了一个习惯，我们自己做个功能，每一个服务背后的意义，或者说梦想在里面到底是什么。如果一个功能纯粹为了流量做，而想不出给用户带来什么价值，这个功能一定是有问题的，或者他是不长远的。我认为正是这样每一块都去想他背后的一丝一毫的意义，这个是支撑起我们整个团队走到今天的一个很强的理由，并且帮助我们做出正确的选择。这是产品和功能背后我们所思考的意义。 说更幸运的是在这个过程里面，把自己对这个世界的认知能够体现在产品中，并且成为一个产品的价值观，这是更加难得的一个事情 万物之中，希望至美。至美之物，永不凋零 如果微信不能给用户带来哪怕多一点点希望，那么我们就没有办法判断我们做的事情到底是对的还是错的，所以它也是我们衡量的一个准则。 By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-14 21:38:10 "},"MORE/DynamicBatching.html":{"url":"MORE/DynamicBatching.html","title":"以静制动 Dynamic Batching","keywords":"","body":"以静制动 Dynamic Batching Authors: 刘思聪 Link: https://zhuanlan.zhihu.com/p/25216368 Tags: Optimization Year: 2017 Motivation 动态图：命令式编程(Imperative)，根据实时需求构建对应的计算图(define-by-run),灵活，方便调试 在NLP等输入不定的情况下，动态图比较符合实际需求 但很多时候效率没有静态图好 静态图：符号式编程(Symbolic), 在计算流程完全定义好后才被执行，提前优化网络，尽可能全局最优 Solution Dynamic Batching 一个模型可以拆分为两种基本组件 Tensor(中间结果，像相同大小和材质的砖头) Operation(中间结果, 计算子图) Dynamic Batching是一个贪婪（greedy）的算法，它接受一个有向无环计算图作为输入: 给图中的每一个节点（操作）标注一个深度，没有任何依赖的节点标注为深度0，依赖的节点深度最大为d的节点的深度标注为d+1； 在图中插入pass-through（直通）的操作，使得第d+1层只依赖于第d层； 将同一深度涉及相同操作的节点合并到一起，方便并行计算； 将同一深度的计算结果按Tensor类型（包括Tensor的形状和数值类型）有序拼接在一起； 将输入原始计算图中的每条边标记上（深度，数据类型，序号），对应它们可以获取上一层计算结果的位置。 将串行变成并行 类似与一个图片大小未知的输入，warmup之后，框架就会大致判断出他的内存消耗！！ By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-14 21:38:10 "},"MORE/MXNet_Adventures.html":{"url":"MORE/MXNet_Adventures.html","title":"MXNet Design Concepts","keywords":"","body":"MXNet Design Concepts Authors: Magic Link: https://mxnet.incubator.apache.org/architecture/index.html Tags: MXNet Year: Alive Need Know DMLC： Distributed (Deep) Machine Learning Community, A Community of Awesome Machine Learning Projects Dependency Engine for Deep Learning Dependency Scheduling: 尽可能做到并行操作 难点： 数据流图中依赖的处理 内存的回收 随机数的生成必须串行 Case Study 逐层的计算 There is a delay in computation between the last backward pass to layer k and the next forward call to layer k. We can synchronize the weight of layer k in parallel with other computation during this delay. 多GPU的参数更新大致分为两步一个是多gpu各自计算梯度回传，然后同步各个gpu相同层的参数 多GPU之间layer k的weight的同步会在下次前向传播到来之前进行 大致的操作： 将两种标签来表示对变量的依赖分为两种： read_vars: 变量中间没有改变 mutate_vars: 变量会在操作中发生改变 为每个变量生成一个依赖的队列，read_vars可以同步的读取 Optimizing Memory Consumption in Deep Learning 显式反向路径法: 正向传递和反向传播不在同一张图上 节省内存，可以跑完节点就释放内存，如果公用需要一直占着 反向传播的路径也可以优化，不一定要是一个正向的镜像 反向传播和正向传递就变成了相同的问题 内存优化的思路： In-place Operations: 就是输入输出共用同一片内存，前提是输入变量不再被其他所依赖 Standard Memory Sharing: 重复使用前面已经不会再被使用的内存，如果这两个共享内存的比变量不一样大，一般会按照大的那个内存分配空间 内存优化重点考虑的是每个量的生命周期，类似于编译器，而且在内存优化的过程中要优先保证安全和正确，同事尽量允许更多的并行， Designing Efficient Data Loaders for Deep Learning 同样的数据，封装成大文件读取比小文件更好，避免了小文件读取的寻址时间！！ 而且打包后可以节省部分空间 By MagicWang，使用知识共享 署名-相同方式共享 4.0协议发布            此页面修订于： 2019-01-18 17:17:08 "}}